<div align="center">

# âš¡ï¸ **Agent Starter**

### *Local AI Autonomy â€” Powered by FastAPI Ã— Ollama (Llama 3)*

[![Python](https://img.shields.io/badge/Python-3.12-blue?logo=python\&logoColor=white)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-Backend-green?logo=fastapi\&logoColor=white)](https://fastapi.tiangolo.com/)
[![Ollama](https://img.shields.io/badge/Ollama-Llama_3-gold?logo=llama\&logoColor=white)](https://ollama.ai/)
[![License: MIT](https://img.shields.io/badge/License-MIT-lightgrey.svg)](LICENSE)

> Build, deploy, and run intelligent agents **fully offline** â€” no APIs, no cloud, no gatekeepers.

</div>

---

<div align="center">

## ğŸš€ **Overview**

</div>

**Agent Starter** is a minimal yet production-ready template for creating local AI agents that can **plan, act, and reflect** using your own hardware.

It includes:

* âš™ï¸ **FastAPI** backend to orchestrate message flow
* ğŸ¤– **Ollama-powered LLMs** (Llama 3, Mistral, etc.) for reasoning and response
* ğŸ§© **Tool interface** (currently `web.fetch`) for real-world actions
* ğŸ§  **Short-term memory** for contextual continuity
* ğŸ” **Sense â†’ Plan â†’ Act â†’ Reflect** control loop
* ğŸŒ Optional live web retrieval & summarization

---
<p align="center">
  <img src="agent_loop_diagram.jpg" alt="Sense â†’ Plan â†’ Act â†’ Reflect loop" width="700"/>
  <br><sub><em>Autonomous loop: Sense â†’ Plan â†’ Act â†’ Reflect</em></sub>
</p>

<div align="center">

## ğŸ’¡ **Quickstart**

</div>

```bash
# 1. Clone and set up
git clone git@github.com:ben-scire/agent-starter.git
cd agent-starter
python -m venv .venv && source .venv/bin/activate
pip install -e .

# 2. Create .env
echo "LLM_PROVIDER=ollama
LLM_MODEL=llama3.1:8b-instruct-q4_K_M
LLM_BASE_URL=http://172.17.128.1:11434" > .env

# 3. Run FastAPI
uvicorn api.main:app --reload --env-file .env

# 4. Test
curl -s http://127.0.0.1:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"query":"Fetch https://en.wikipedia.org/wiki/Artificial_intelligence and summarize it."}'
```

---

<div align="center">

## ğŸ§© **Architecture & Example**

</div>

#### **Agent Flow**

```
FastAPI  (api/main.py)
â””â”€â”€ SingleAgent.run()
    â”œâ”€â”€ Plan â†’ uses Llama (via Ollama)
    â”œâ”€â”€ Act  â†’ calls allowed tools (e.g., web.fetch)
    â”œâ”€â”€ Reflect â†’ evaluates and summarizes
    â””â”€â”€ Memory â†’ stores short-term context
```

Llama 3 runs locally via Ollama at `http://127.0.0.1:11434`.

#### **Example Query**

```bash
curl -s http://127.0.0.1:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"query":"Summarize https://en.wikipedia.org/wiki/Quantum_computing in 2 sentences."}'
```

#### **Example Response**

```json
{
  "summary": "Quantum computing leverages quantum-mechanical phenomena to perform computations that are infeasible for classical systems. It promises exponential speedups for specific problems like factorization and simulation.",
  "citations": []
}
```

---

<div align="center">

## ğŸ§° **Core Components**

</div>

| **Feature**      | **File**         | **Description**                   |
| ---------------- | ---------------- | --------------------------------- |
| Core agent logic | `core/agent.py`  | Sense â†’ Plan â†’ Act â†’ Reflect loop |
| Memory manager   | `core/memory.py` | Stores contextual exchanges       |
| LLM interface    | `core/llm.py`    | Routes messages to Ollama         |
| Web tool         | `tools/web.py`   | Fetch + clean webpage text        |
| API endpoint     | `api/main.py`    | FastAPI routes for `/chat`        |

Add new tools (filesystem, browser automation, crypto APIs, etc.) and plug them into the `allowed_tools` whitelist.

---

<div align="center">

## ğŸ§‘â€ğŸ’» **Why This Matters**

</div>

Most â€œagent frameworksâ€ hide behind APIs and paywalls.
This one runs *entirely local*, letting you:

* Inspect every request and response
* Prototype new agent behaviors
* Benchmark real LLM latency on-device
* Run safely offline

Itâ€™s built for engineers who want transparency and total control over their agents.

---

<div align="center">

## ğŸª„ **Coming Soon**

</div>

* Multi-agent orchestration (Maestro, Scrubsy, Vegas)
* Persistent memory store
* CLI + simple web UI
* Optional GPU inference benchmark mode

---

<div align="center">

## âš–ï¸ **License**

</div>

MIT Â© 2025 Ben Scire

---

<p align="center"><sub>â€œBuild tools, not dependencies.â€</sub></p>
